{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,shutil,sys\n",
    "sys.path.append('/data/py/lib/') \n",
    "import keras\n",
    "import time\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import xception\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "####定义一些常用的训练调整参数###########\n",
    "epochs=13          #定义训练轮数\n",
    "batch_size=20       #每批数量\n",
    "lock_layer_num=70;   #锁住的层数\n",
    "lr=1e-4             #学习率\n",
    "dense_num=256       #连接层数量\n",
    "pre_train_epochs=1#预训练轮数,0表示不进行预训练\n",
    "img_height=299      #训练图片高度\n",
    "img_width=299       #训练图片宽度\n",
    "is_load_model=False #是否加载自己训练的历史模型\n",
    "model_path=\"/data/keras/models/01281643.h\"\n",
    "##########################\n",
    "\n",
    "base_dir='/data/keras/download/hua'\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "validation_dir=os.path.join(base_dir,'validation')\n",
    "test_dir=os.path.join(base_dir,'test')\n",
    "\n",
    "\n",
    "mod_names=[\"月季花\",\"蝴蝶兰\",\"海棠花\",\"桂花\",\"发财树\",\"米仔兰\",\"一品红\",\"九里香\",\"茶花\",\"巴西铁树\"]\n",
    "\n",
    "mod_num=len(mod_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2990 images belonging to 10 classes.\n",
      "Found 497 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#使用图片数据增强，降低拟合的有效手段\n",
    "train_datagen=ImageDataGenerator(  \n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "#验证，测试数据不能进行数据增强\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'   \n",
    ")\n",
    "\n",
    "validation_generator=test_datagen.flow_from_directory(   \n",
    "    validation_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(   \n",
    "    test_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150/149 [==============================] - 55s 365ms/step - loss: 1.8827 - acc: 0.4230 - val_loss: 1.5936 - val_acc: 0.4628\n",
      "Epoch 1/13\n",
      "150/149 [==============================] - 54s 360ms/step - loss: 0.7983 - acc: 0.7457 - val_loss: 0.5390 - val_acc: 0.8290\n",
      "Epoch 2/13\n",
      "  3/149 [..............................] - ETA: 44s - loss: 0.4742 - acc: 0.8667"
     ]
    }
   ],
   "source": [
    "if is_load_model is False:\n",
    "    # 构建不带分类器的预训练模型\n",
    "    base_model = xception.Xception(weights=\"imagenet\",include_top=False,input_shape=(img_height,img_width,3))\n",
    "\n",
    "    # 添加全局平均池化层\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # 添加一个全连接层\n",
    "    x = Dense(dense_num, activation='relu')(x)\n",
    "\n",
    "    # 添加一个分类器\n",
    "    predictions = Dense(mod_num, activation='softmax')(x)\n",
    "\n",
    "    # 构建我们需要训练的完整模型\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # 锁住所有 Xception 的卷积层\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #预训练\n",
    "    if pre_train_epochs>0:\n",
    "        model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='categorical_crossentropy',metrics=['acc'])\n",
    "        history=model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "            epochs=pre_train_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "        )\n",
    "\n",
    "    # 现在顶层应该训练好了，开始微调 Xception的卷积层。\n",
    "    # 锁住底下的几层，然后训练其余的顶层。\n",
    "    # 看看每一层的名字和层号，看看我们应该锁多少层呢：\n",
    "    # for i, layer in enumerate(base_model.layers):\n",
    "    #    print(i, layer.name)\n",
    "\n",
    "    # 锁住的层数\n",
    "    for layer in model.layers[:lock_layer_num]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[lock_layer_num:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "    # 设置一个很低的学习率，使用 SGD 来微调\n",
    "    from keras.optimizers import SGD\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=lr), loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "    # 继续训练模型\n",
    "    history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "    )\n",
    "    #保存训练好的模型\n",
    "    time_t=time.strftime(\"%m%d%H%M\", time.localtime()) \n",
    "    model.save('/data/keras/models/%s.h'%time_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_generator.n/train_generator.batch_size,\n",
    "#     epochs=5,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_generator.n/validation_generator.batch_size\n",
    "# )\n",
    "# #保存训练好的模型\n",
    "# time_t=time.strftime(\"%m%d%H%M\", time.localtime()) \n",
    "# model.save('/data/keras/models/%s.h'%time_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示训练过程中精度变化\n",
    "if is_load_model is False:\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    epochs=range(1,len(acc)+1)\n",
    "    plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "    plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "else:\n",
    "    model=keras.models.load_model(\"/data/keras/models/01281643.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集评估\n",
    "test_loss,test_acc=model.evaluate_generator(test_generator,steps=test_generator.n/test_generator.batch_size)\n",
    "print (\"测试集 acc:%f\" % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#显示真实收集的图片的结果\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mytool import MyTool\n",
    "test_imgs=['/data/test/hua/蝴蝶兰1.jpg',\n",
    "           '/data/test/hua/蝴蝶兰2.jpg',\n",
    "           '/data/test/hua/蝴蝶兰3.jpg',\n",
    "           '/data/test/hua/茶花2.jpg',\n",
    "           '/data/test/hua/茶花3.jpg',\n",
    "           '/data/test/hua/茶花4.jpg',\n",
    "           '/data/test/hua/茶花5.jpg',\n",
    "           '/data/test/hua/桂花1.jpg',\n",
    "            '/data/test/hua/桂花2.jpg',\n",
    "            '/data/test/hua/一品红1.jpg',\n",
    "           '/data/test/hua/一品红2.jpg',\n",
    "           '/data/test/hua/一品红3.jpg',\n",
    "           '/data/test/hua/米仔兰2.jpg',\n",
    "           '/data/test/hua/米仔兰3.jpg',\n",
    "           '/data/test/hua/九里香1.jpg',\n",
    "           '/data/test/hua/九里香2.jpg',\n",
    "           '/data/test/hua/海棠花2.jpg',\n",
    "           '/data/test/hua/海棠花3.jpg',\n",
    "           '/data/test/hua/巴西铁树1.jpg',\n",
    "           '/data/test/hua/巴西铁树2.jpg',\n",
    "           '/data/test/hua/发财树1.jpg',\n",
    "           '/data/test/hua/发财树2.jpg',\n",
    "           '/data/test/hua/发财树3.jpg',\n",
    "           '/data/test/hua/月季花3.jpg',\n",
    "           '/data/test/hua/月季花4.jpg',\n",
    "           '/data/test/hua/月季花7.jpg',\n",
    "           '/data/test/hua/月季花8.jpg',\n",
    "           '/data/test/hua/月季花9.jpg',\n",
    "           '/data/test/hua/月季花10.jpg',\n",
    "           '/data/test/hua/月季花11.jpg',\n",
    "          ]\n",
    "\n",
    "for img_path in test_imgs:\n",
    "    #img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img =cv2.imread(img_path)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    img=MyTool.cro_img(img,img_height,img_width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x=x/255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    paixu=dict(zip(train_generator.class_indices,preds[0]))\n",
    "    paixu= sorted(paixu.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"图片：\",img_path)\n",
    "    print(\"预测：\",paixu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
